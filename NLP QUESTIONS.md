QUESTIONS  :

1. How would you handle ambiguous or missing medical data in the transcript?

Ans.:   There are various  ways to handle ambiguous data like ,

1. We can use pre-trained NER models like MedSpaCy, BioBert, ScispaCy.  
2. We can use default values for unstated data.  
3. For critical medical data we can incorporate human physicians.

2.What pre-trained NLP models would you use for medical summarization?  
Ans: The pre-trained NLP models are BioBERT ,ClinicalBERT ,MedGPT, T5.

3.How would you fine-tune BERT for medical sentiment detection?  
Ans.: The steps for fine-tuning BERT are,  
        1.Data Preparation .  
        2\. Model setup & Fine tuning.  
        3.Inference on New medical transcripts.

4.What datasets would you use for training a healthcare-specific sentiment model?  
Ans: Best datasets for training a healthcare \- specific sentiment model are,  
1.MIMIC-III  
2.i2b2 Clinical NLP Dataset   
3.MEDLINE & PubMed Abstracts  
4\. Care Corpus.

5.How would you train an NLP model to map medical transcripts into SOAP format?  
Ans: Steps to train an NLP model to map medical transcripts into SOAP format:

1. Data Preparation  
2. Model Selection & Fine Tuning

6.What rule-based or deep-learning techniques would improve the accuracy of SOAP note generation?  
Ans:  Rule based or deep learning techniques use to improve the accuracy of SOAP note generation are ,

Rule Based Learning:  
1.Regular Expressions  
2.Name Entity Recognition  
3.Ontology based mapping.

Deep Learning Techniques:  
1.Transformer Based Summarization (BERT,/T5/GPT-4)  
2.Few-Shot Learning with GPT-4

